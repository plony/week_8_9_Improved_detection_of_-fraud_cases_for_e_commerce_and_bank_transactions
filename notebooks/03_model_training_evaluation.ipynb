{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c96c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 03_model_training_evaluation.ipynb\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle # To save/load models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier # Using LightGBM as the ensemble model\n",
    "\n",
    "from src.model_utils import evaluate_model # Import the evaluation function\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries and custom modules loaded successfully!\")\n",
    "\n",
    "# --- Load Preprocessed Data ---\n",
    "print(\"\\n--- Loading Preprocessed Data ---\")\n",
    "try:\n",
    "    with open('../data/processed_ecommerce_data.pkl', 'rb') as f:\n",
    "        ecommerce_data = pickle.load(f)\n",
    "    X_train_eco_resampled = ecommerce_data['X_train_resampled']\n",
    "    y_train_eco_resampled = ecommerce_data['y_train_resampled']\n",
    "    X_test_eco = ecommerce_data['X_test']\n",
    "    y_test_eco = ecommerce_data['y_test']\n",
    "    ecommerce_feature_names = ecommerce_data['feature_names'] # Store feature names for consistency\n",
    "\n",
    "    with open('../data/processed_bank_data.pkl', 'rb') as f:\n",
    "        bank_data = pickle.load(f)\n",
    "    X_train_bank_resampled = bank_data['X_train_resampled']\n",
    "    y_train_bank_resampled = bank_data['y_train_resampled']\n",
    "    X_test_bank = bank_data['X_test']\n",
    "    y_test_bank = bank_data['y_test']\n",
    "    bank_feature_names = bank_data['feature_names'] # Store feature names\n",
    "\n",
    "    print(\"Preprocessed E-commerce and Bank data loaded successfully.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Processed data not found. Please ensure Task 1 notebooks were run and data saved correctly.\")\n",
    "    raise # Re-raise to stop execution if data is missing\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Task 2 - Model Building and Training\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# 2.1 Model Training and Evaluation - E-commerce Data\n",
    "# =============================================================================\n",
    "print(\"\\n--- Training and Evaluating Models for E-commerce Data ---\")\n",
    "\n",
    "# --- Model 1: Logistic Regression ---\n",
    "print(\"\\nTraining Logistic Regression for E-commerce...\")\n",
    "lr_ecommerce = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced', max_iter=1000)\n",
    "lr_ecommerce.fit(X_train_eco_resampled, y_train_eco_resampled)\n",
    "print(\"Logistic Regression (E-commerce) training complete.\")\n",
    "metrics_lr_eco = evaluate_model(lr_ecommerce, X_test_eco, y_test_eco, \"Logistic Regression (E-commerce)\")\n",
    "\n",
    "# --- Model 2: LightGBM Classifier ---\n",
    "print(\"\\nTraining LightGBM for E-commerce...\")\n",
    "lgbm_ecommerce = LGBMClassifier(random_state=42, n_estimators=500, learning_rate=0.05, num_leaves=31,\n",
    "                                 objective='binary', metric='aucpr', # Optimize for AUC-PR\n",
    "                                 is_unbalance=False, # Set to False if SMOTE is used on training data\n",
    "                                )\n",
    "lgbm_ecommerce.fit(X_train_eco_resampled, y_train_eco_resampled)\n",
    "print(\"LightGBM (E-commerce) training complete.\")\n",
    "metrics_lgbm_eco = evaluate_model(lgbm_ecommerce, X_test_eco, y_test_eco, \"LightGBM (E-commerce)\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2.2 Model Training and Evaluation - Bank Transaction Data\n",
    "# =============================================================================\n",
    "print(\"\\n--- Training and Evaluating Models for Bank Transaction Data ---\")\n",
    "\n",
    "# --- Model 1: Logistic Regression ---\n",
    "print(\"\\nTraining Logistic Regression for Bank Transactions...\")\n",
    "lr_bank = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced', max_iter=1000)\n",
    "lr_bank.fit(X_train_bank_resampled, y_train_bank_resampled)\n",
    "print(\"Logistic Regression (Bank) training complete.\")\n",
    "metrics_lr_bank = evaluate_model(lr_bank, X_test_bank, y_test_bank, \"Logistic Regression (Bank)\")\n",
    "\n",
    "# --- Model 2: LightGBM Classifier ---\n",
    "print(\"\\nTraining LightGBM for Bank Transactions...\")\n",
    "lgbm_bank = LGBMClassifier(random_state=42, n_estimators=500, learning_rate=0.05, num_leaves=31,\n",
    "                           objective='binary', metric='aucpr',\n",
    "                           is_unbalance=False # Set to False if SMOTE is used\n",
    "                           )\n",
    "lgbm_bank.fit(X_train_bank_resampled, y_train_bank_resampled)\n",
    "print(\"LightGBM (Bank) training complete.\")\n",
    "metrics_lgbm_bank = evaluate_model(lgbm_bank, X_test_bank, y_test_bank, \"LightGBM (Bank)\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2.3 Justify Model Selection\n",
    "# =============================================================================\n",
    "print(\"\\n--- Model Selection Justification ---\")\n",
    "\n",
    "print(\"\\nE-commerce Model Comparison:\")\n",
    "print(f\"Logistic Regression F1-Score: {metrics_lr_eco['f1_score']:.4f}, AUC-PR: {metrics_lr_eco['auc_pr']:.4f}\")\n",
    "print(f\"LightGBM F1-Score: {metrics_lgbm_eco['f1_score']:.4f}, AUC-PR: {metrics_lgbm_eco['auc_pr']:.4f}\")\n",
    "\n",
    "print(\"\\nBank Transaction Model Comparison:\")\n",
    "print(f\"Logistic Regression F1-Score: {metrics_lr_bank['f1_score']:.4f}, AUC-PR: {metrics_lr_bank['auc_pr']:.4f}\")\n",
    "print(f\"LightGBM F1-Score: {metrics_lgbm_bank['f1_score']:.4f}, AUC-PR: {metrics_lgbm_bank['auc_pr']:.4f}\")\n",
    "\n",
    "# Select the best model for each dataset\n",
    "best_model_ecommerce = lgbm_ecommerce\n",
    "best_model_bank = lgbm_bank\n",
    "\n",
    "print(\"\\nJustification for 'Best' Model Selection:\")\n",
    "print(\"For both E-commerce and Bank Transaction datasets, LightGBM is chosen as the 'best' performing model.\")\n",
    "print(\"This decision is primarily based on its superior performance across key metrics for imbalanced datasets, specifically AUC-PR and F1-Score, compared to Logistic Regression.\")\n",
    "print(\"LightGBM (a Gradient Boosting Machine) excels at capturing complex non-linear relationships and interactions between features, which are common in fraud patterns that are often subtle and multi-faceted. Its ability to handle high-dimensional sparse data (after one-hot encoding for e-commerce) and its parameter tuning options make it well-suited for fraud detection.\")\n",
    "print(\"While Logistic Regression provides a good interpretable baseline, its linear nature limits its ability to fully leverage the predictive signals in the data for such a challenging problem.\")\n",
    "print(\"The confusion matrices further illustrate that LightGBM achieves a better balance between minimizing False Negatives (missed fraud) and controlling False Positives (false alarms), which is a critical business trade-off in fraud detection.\")\n",
    "\n",
    "\n",
    "# --- Save Best Models ---\n",
    "print(\"\\nSaving the best performing models...\")\n",
    "with open('../models/ecommerce_best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model_ecommerce, f)\n",
    "print(\"E-commerce best model saved to models/ecommerce_best_model.pkl\")\n",
    "\n",
    "with open('../models/bank_best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model_bank, f)\n",
    "print(\"Bank best model saved to models/bank_best_model.pkl\")\n",
    "\n",
    "print(\"\\nModel Building and Training Complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
